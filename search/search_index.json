{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":""},{"location":"#numerflow-a-framework-for-automated-pipelines-for-the-numerai-tournament","title":"NumerFlow - A Framework for Automated Pipelines for the NumerAI Tournament","text":"<p>NumerFlow is an open-source modular framework designed for automating pipelines for the NumerAI tournament. It provides a simple and abstract interface to create workflows, allowing users to focus on model development and key pipeline steps rather than tedious workflow scripting.</p>"},{"location":"#features","title":"Features","text":"<ul> <li>Abstract Interface: Provides a modular interface for defining pipeline steps supporting multiple workflows for a wide range of tasks. Easily define complex workflows with prescriptive primitives while offering a flexible methodology to rapidly build and test ideas. </li> <li>Modular Building Blocks: NumerFlow's consistent and easy-to-understand interface (fit, transform, predict) enables users to create modules and leverage existing code to avoid re-writing standard tasks.</li> <li>Model Stacking: Uses models' predictions as features to downstream meta-models where training data does not overlap.</li> <li>Model Features: Out-of-fold model CV predictors</li> <li>Feature Neutralization: Reduce feature exposure to reduce inconsistent predictions over time.</li> <li>Simple Deployment: NumerFlow manages all task states for both training and inference. Simply call the predict method on the fitted pipeline.</li> <li>Combination or Direct: Workflow definitions can easily be created by the product combination or direct one-to-one mapping of each type, increasing prediction variance by ensembling various types of models, data partitions, targets, and feature selection.</li> <li>Retrain: Easily retrain the pipeline on full dataset while maintaining original fit parameters</li> <li>Hyperparameter Optimization: Optimize any model easily with Optuna.</li> <li>Cache: Utilizes cache to speed up development for long-running tasks.</li> <li>Report: Comprehensive HTML report of completed workflow</li> </ul>"},{"location":"#pipeline-steps","title":"Pipeline Steps","text":"<p>A pipeline is simply a collection of workflows each consisting of tasks.  Each workflow's tasks are defined by a series of steps.  Each step is a standardized modular block of code that appropriately handles the step function:  </p> <ul> <li>Preprocess: Modifies the data before it is partitioned in the workflow. For example, you may want to create additional features from out of sample model predictions.  This optional step manipulates the entire data set before it is partitioned in the workflow.</li> <li>Partitions: Partitions carve out specific portions of the data for each task.  For example, creating data partitions of every Nth era. </li> <li>Features: For each data partition, you can easily add additional features</li> <li>Transforms: Manipulate the data partitions without changing its shape</li> <li>Selectors:  Feature reduction per data partition.</li> <li>Targets:  Customized targets</li> <li>Models:  Customized models</li> </ul>"},{"location":"#simple-example","title":"Simple Example","text":"<p>The following reproduces the example model provided by Numerai:</p> <pre><code>parameters = {\n    \"n_estimators\": 2000,\n    \"learning_rate\": 0.01,\n    \"max_depth\": 5,\n    \"num_leaves\": 2 ** 5,\n    \"seed\": 123,\n    \"colsample_bytree\": 0.1\n}\n\nX_train, y_train, X_test, y_test = NAPI().split()\npipeline = Numerflow(\n                    neutralize=0.5,\n                    workflow=[{\n                        'selectors': [\n                            FeatureSet(\"medium\")\n                        ],\n                        \"models\": [\n                            LGB(parameters=parameters)\n                        ],\n                    }])\npipeline = pipeline.fit(X_train, y_train)\npredictions = pipeline.predict(X_test, label=y_test.target)\n</code></pre> <p>Note the following defaults:</p> <ul> <li>Neutralization uses half/half method where risky features are determined by comparing mean correlations of the first half of eras to the second half.</li> <li>Since no partitions were defined, all of the training data was used to train the LGB model</li> <li>Since no targets were defined, Cyrus was used to train the LGB Model</li> </ul>"},{"location":"#documentation","title":"Documentation","text":"<ul> <li>Installation</li> <li>Quick Start</li> <li>Understanding Pipelines</li> <li>Creating Modules</li> </ul>"},{"location":"#why-numerflow","title":"Why NumerFlow?","text":"<p>Creating custom pipelines for testing ideas can be cumbersome, complex and prone to errors. Traditional methods involve maintaining multiple large pipeline scripts and injecting relevant code, making it difficult to manage as complexity increases. A framework that calls the fit and predict of modular code while hiding the pipeline complexity provides a much more efficient test and deploy methodology. NumerFlow makes it easy to create complex pipelines with low effort while making idea development significantly easier. Over time, Numerflow builds a collection of organized and reusable code for pipeline modules such as models, targets, features, selection, etc.</p> <p>Overall, NumerFlow is a powerful and flexible framework that simplifies the process of building and testing pipelines for the NumerAI tournament, making it easier for users to focus on model development and key pipeline steps.</p>"},{"location":"install/","title":"Installation","text":"<p>The best method to install NumerFlow is to clone the repo and <code>pip install -e</code> from source.  This enables active development from local source code while still using the package as if it were installed:</p> <pre><code>git clone https://github.com/jmrichardson/fml.git\ncd fml\nconda create --name fml python=3.8 -y\nconda activate fml\npip install --use-deprecated=legacy-resolver -e .\npip install --force-reinstall --no-cache-dir --no-deps TA-Lib==0.4.24\n</code></pre>"},{"location":"modules/","title":"Creating Modules","text":""},{"location":"modules/#creating-modules","title":"Creating Modules","text":"<p>Modules are the building blocks of NumerFlow pipelines.  Creating a module starts by simply using boiler plate code with a fit and predict or transform interface. The easiest way to start is to copy a similar module's file and remove the existing code.  There are a few things to keep in mind:</p> <ul> <li>Some modules have caching code to reduce long running time.  If your module doesn't take significant time to execute then this code can be removed.  </li> <li>Fit functions are provided both the era and label for the data partition.  Predict and transform do not include the label</li> <li>There is minimal error checking in the pipeline for data integrity.  It is advisable to use debug stop points to ensure returned data is accurate.</li> </ul>"},{"location":"pipelines/","title":"Understanding Pipelines","text":""},{"location":"pipelines/#understanding-pipelines","title":"Understanding Pipelines","text":"<p>FML defines a pipeline as a collection of workflows each consisting of individual tasks.  A task is defined by an associated user created module.</p> <p>The following types of modules can be used to define a workflow.</p> <ul> <li>Preprocess: modifies the data before it is partitioned in a workflow</li> <li>Partitions: splits the training data</li> <li>Features: appends new features to existing features in the data partition</li> <li>Transforms: transforms the data features</li> <li>Select: Feature reduction</li> <li>Target: training target</li> <li>Model: build model</li> </ul> <p>Partitions, Select, Target and Model modules determine the number of tasks per workflow.  The number of tasks is the combination of each of these modules.  For example, if your workflow has 2 partitions, 2 selects, 3 targets and 3 models will result in 36 tasks for the workflow:</p> <pre><code>2 * 2 * 3 * 3 = 36\n</code></pre> <p>In other words, a total of 36 unique models will be created.   It's important to note that features and transforms modules will be performed on each of the 36 tasks in the workflow but do not create unique tasks.  Preprocess occurs once for the entire workflow and therefore also doesn't create unique tasks.    </p> <p>Note, If you would prefer to manually control  generated features for separate models as opposed to feature selection, define multiple workflows.  The flexibility of multiple workflows allows for limitless customization of the pipeline.</p>"},{"location":"quick_start/","title":"Quick Start","text":""},{"location":"quick_start/#quick-start","title":"Quick Start","text":"<p>Let's build a NumerAI tournament pipeline with the following architecture:</p> <p>Use all training data Use nomi 20 day target  LGBM with NumerAI default parameters </p> <p>Let's try to improve the pipeline:</p> <p>Partition training data using every 4th era for a total of 4 training sets.  Train each model using the average of all the provided 20 day targets. Use LGBM model with default NumerAI parameters Ensemble all model predictions with modern portfolio optimization weights</p> <p>Now we can improve the pipeline a bit more:</p> <p>Use the entire training data set as well as every 4th era Increase the number of trees to 4000 instead of 2000 Neutralize features</p>"}]}